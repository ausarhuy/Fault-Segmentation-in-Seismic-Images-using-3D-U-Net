{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-03T15:40:21.970824700Z",
     "start_time": "2023-07-03T15:40:21.952824600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def unet(input_size=(None, None, None, 1)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv3D(16, (3, 3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv3D(16, (3, 3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(conv4)\n",
    "\n",
    "    up5 = concatenate([UpSampling3D(size=(2, 2, 2))(conv4), conv3], axis=-1)\n",
    "    conv5 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(up5)\n",
    "    conv5 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([UpSampling3D(size=(2, 2, 2))(conv5), conv2], axis=-1)\n",
    "    conv6 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([UpSampling3D(size=(2, 2, 2))(conv6), conv1], axis=-1)\n",
    "    conv7 = Conv3D(16, (3, 3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv3D(16, (3, 3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    conv8 = Conv3D(1, (1, 1, 1), activation='sigmoid')(conv7)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv8])\n",
    "    model.summary()\n",
    "    # model.compile(optimizer = Adam(lr = 1e-4),\n",
    "    # loss = cross_entropy_balanced, metrics = ['accuracy'])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T15:40:22.018956800Z",
     "start_time": "2023-07-03T15:40:21.970824700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def data_norm(image):\n",
    "    mean = np.mean(image)\n",
    "    std = np.std(image)\n",
    "    return (image - mean) / std"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T15:40:22.019958800Z",
     "start_time": "2023-07-03T15:40:21.976833200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def show_history(history):\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model accuracy', fontsize=20)\n",
    "    plt.ylabel('Accuracy', fontsize=20)\n",
    "    plt.xlabel('Epoch', fontsize=20)\n",
    "    plt.legend(['train', 'test'], loc='center right', fontsize=20)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "    plt.tick_params(axis='both', which='minor', labelsize=18)\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss', fontsize=20)\n",
    "    plt.ylabel('Loss', fontsize=20)\n",
    "    plt.xlabel('Epoch', fontsize=20)\n",
    "    plt.legend(['train', 'test'], loc='center right', fontsize=20)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "    plt.tick_params(axis='both', which='minor', labelsize=18)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T15:40:22.019958800Z",
     "start_time": "2023-07-03T15:40:21.997344400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def load_sample(file_path, shape=(128, 128, 128), dtype=np.single, norm=True):\n",
    "    sample = np.fromfile(file_path, dtype=dtype).reshape(shape)\n",
    "    if norm:\n",
    "        sample = data_norm(sample)\n",
    "    # In seismic processing, the dimensions of a seismic array is often arranged as\n",
    "    # a[n3][n2][n1] where n1 represents the vertical dimension.\n",
    "    return np.transpose(sample)\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    \"\"\"Generates data for keras\"\"\"\n",
    "\n",
    "    def __init__(self, path, ids, batch_size=1, shape=(128, 128, 128),\n",
    "                 n_channels=1, shuffle=True):\n",
    "        \"\"\"Initialization\"\"\"\n",
    "        self.shape = shape\n",
    "        self.path = path\n",
    "        self.batch_size = batch_size\n",
    "        self.ids = ids\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return int(np.floor(len(self.ids) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates one batch of data\"\"\"\n",
    "        # Generate indexes of the batch\n",
    "        bsize = self.batch_size\n",
    "        indexes = self.indexes[index * bsize:(index + 1) * bsize]\n",
    "\n",
    "        # Find list of IDs\n",
    "        ids = [self.ids[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, Y = self.__data_generation(ids)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\"\"\"\n",
    "        self.indexes = np.arange(len(self.ids))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, ids):\n",
    "        \"\"\"Generates data containing batch_size samples\"\"\"\n",
    "        # Initialization\n",
    "        seis = load_sample(f'{self.path}/seis/{ids[0]}.dat', norm=True)\n",
    "        fault = load_sample(f'{self.path}/fault/{ids[0]}.dat', norm=False)\n",
    "        seis = np.reshape(seis, self.shape)\n",
    "\n",
    "        # Generate data\n",
    "        X = np.zeros((2, *self.shape, self.n_channels), dtype=np.single)\n",
    "        Y = np.zeros((2, *self.shape, self.n_channels), dtype=np.single)\n",
    "        X[0,] = np.reshape(seis, (*self.shape, self.n_channels))\n",
    "        Y[0,] = np.reshape(fault, (*self.shape, self.n_channels))\n",
    "        X[1,] = np.reshape(np.flipud(seis), (*self.shape, self.n_channels))\n",
    "        Y[1,] = np.reshape(np.flipud(fault), (*self.shape, self.n_channels))\n",
    "        '''\n",
    "        for i in range(4):\n",
    "          X[i,] = np.reshape(np.rot90(seis,i,(2,1)), (*self.shape,self.n_channels))\n",
    "          Y[i,] = np.reshape(np.rot90(fault,i,(2,1)), (*self.shape,self.n_channels))\n",
    "        '''\n",
    "        return X, Y\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T15:40:22.023955700Z",
     "start_time": "2023-07-03T15:40:22.017957500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2468655728.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[16], line 15\u001B[1;36m\u001B[0m\n\u001B[1;33m    with tf.de\u001B[0m\n\u001B[1;37m              ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "params = {'batch_size': 1,\n",
    "          'shape': (128, 128, 128),\n",
    "          'n_channels': 1,\n",
    "          'shuffle': True}\n",
    "train_path = \"./data/train/\"\n",
    "val_path = \"./data/validation/\"\n",
    "\n",
    "train_ids = range(len(os.listdir(train_path)))\n",
    "val_ids = range(len(os.listdir(val_path)))\n",
    "train_generator = DataGenerator(path=train_path,\n",
    "                                ids=train_ids, **params)\n",
    "valid_generator = DataGenerator(path=val_path,\n",
    "                                ids=val_ids, **params)\n",
    "model = unet(input_size=(None, None, None, 1))\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss='bce',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# checkpoint\n",
    "filepath = \"model/model-{epoch:02d}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc',\n",
    "                             verbose=1, save_best_only=False, mode='max')\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                              patience=20, min_lr=1e-8)\n",
    "callbacks_list = [checkpoint]\n",
    "print(\"data prepared, ready to train!\")\n",
    "# Fit the model\n",
    "history = model.fit(train_generator,\n",
    "                    validation_data=valid_generator, epochs=1, callbacks=callbacks_list, verbose=1)\n",
    "model.save('model/model.h5')\n",
    "show_history(history)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T15:40:22.100024600Z",
     "start_time": "2023-07-03T15:40:22.080961800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-03T15:40:22.084962Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
